{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixture component weights\n",
      "[ 0.75  0.25]\n",
      "\n",
      "mixture component mean vectors\n",
      "[[  9.95979962  10.04835949]\n",
      " [  0.22665544  -0.01327782]]\n",
      "\n",
      "mixture component covariance matrices\n",
      "[[[ 1.04862299 -0.10230272]\n",
      "  [-0.10230272  1.05411687]]\n",
      "\n",
      " [[ 0.73906418 -0.11445233]\n",
      "  [-0.11445233  0.89051922]]]\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "## set up the reference model for demo purposes\n",
    "##############################################################################################\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import mixture\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "g = mixture.GMM(covariance_type=\"full\", n_components=2)\n",
    "\n",
    "dimensions = 2\n",
    "\n",
    "obs = np.concatenate((np.random.randn(100, dimensions), 10 + np.random.randn(300, dimensions)))\n",
    "\n",
    "g.fit(obs) \n",
    "\n",
    "print \"mixture component weights\\n%s\\n\" % g.weights_\n",
    "\n",
    "print \"mixture component mean vectors\\n%s\\n\" % g.means_\n",
    "\n",
    "print \"mixture component covariance matrices\\n%s\" % g.covars_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "[ 4.62434536  2.38824359]\n",
      "\n",
      "scipy GMM pdf\n",
      "[[  3.94305515e-12   1.00000000e+00]]\n",
      "scipy GMM log pr\n",
      "[-21.53236115]\n",
      "\n",
      "mixture component 0\n",
      "  mixture weight 0.750000\n",
      "  mean vector\n",
      "[  9.95979962  10.04835949]\n",
      "  precision matrix\n",
      "[[ 0.96274704  0.09343522]\n",
      " [ 0.09343522  0.95772936]]\n",
      "  scale coefficient 0.152101\n",
      "\n",
      "mixture component 1\n",
      "  mixture weight 0.250000\n",
      "  mean vector\n",
      "[ 0.22665544 -0.01327782]\n",
      "  precision matrix\n",
      "[[ 1.38053969  0.1774313 ]\n",
      " [ 0.1774313   1.14574442]]\n",
      "  scale coefficient 0.198163\n",
      "\n",
      "calculated Gaussian pdf\n",
      "[  3.94305515e-12   1.00000000e+00]\n",
      "calculated pr\n",
      "4.45260707191e-10\n",
      "calculated log pr\n",
      "-21.5323611465\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "## method #1: directly compute Mahalanobis distance from stored precision matrix and scale\n",
    "## by stored determinant\n",
    "##############################################################################################\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import constants\n",
    "\n",
    "numberOfMixtureComponents = g.n_components\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "sample = (3 + np.random.randn(1, dimensions))[0]\n",
    "\n",
    "print \"sample\\n%s\" % sample\n",
    "\n",
    "print\n",
    "\n",
    "print \"scipy GMM pdf\\n%s\" % g.predict_proba([ sample ])\n",
    "\n",
    "print \"scipy GMM log pr\\n%s\" % g.score([ sample ])\n",
    "\n",
    "# store the pdf of each mixture component\n",
    "gaussianPDF = []\n",
    "\n",
    "# store the sum of the pdfs\n",
    "gaussianPDFSum = 0\n",
    "\n",
    "for mixtureComponentIndex in range(numberOfMixtureComponents):\n",
    "    print \"\\nmixture component %i\" % mixtureComponentIndex\n",
    "    \n",
    "    # 1. get the given parameters for the current mixture component\n",
    "    mixtureWeight = g.weights_[mixtureComponentIndex]\n",
    "\n",
    "    print \"  mixture weight %f\" % mixtureWeight\n",
    "    \n",
    "    meanVector = g.means_[mixtureComponentIndex]\n",
    "    \n",
    "    print \"  mean vector\\n%s\" % meanVector\n",
    "    \n",
    "    covarianceMatrix = g.covars_[mixtureComponentIndex]\n",
    "    \n",
    "    precisionMatrix = linalg.inv(covarianceMatrix)\n",
    "    \n",
    "    print \"  precision matrix\\n%s\" % precisionMatrix\n",
    "    \n",
    "    determinant = linalg.det(covarianceMatrix)\n",
    "    \n",
    "    numberOfDimensions = len(meanVector)\n",
    "    \n",
    "    # 2. center the data sample:\n",
    "    centeredSample = []\n",
    "    \n",
    "    for i in range(numberOfDimensions):\n",
    "        sampleValue = sample[i]\n",
    "        \n",
    "        mean = meanVector[i]\n",
    "        \n",
    "        centeredSampleValue = sampleValue - mean\n",
    "        \n",
    "        centeredSample.append(centeredSampleValue)\n",
    "    \n",
    "    # 3. form the scale coefficient\n",
    "    scale = np.power((2 * constants.pi), numberOfDimensions)\n",
    "    \n",
    "    scale = scale * determinant\n",
    "    \n",
    "    scale = 1.0 / np.sqrt(scale)\n",
    "    \n",
    "    print \"  scale coefficient %f\" % scale\n",
    "        \n",
    "    # 4. perform the vector-matrix-vector Mahalanobis distance calculation\n",
    "    distanceTemp = []\n",
    "    \n",
    "    for i in range(numberOfDimensions):\n",
    "        distanceValue = 0\n",
    "        \n",
    "        for j in range(numberOfDimensions):\n",
    "            centeredSampleValue = centeredSample[j]\n",
    "            \n",
    "            precisionValue = precisionMatrix[j][i]\n",
    "            \n",
    "            tempValue = centeredSampleValue * precisionValue\n",
    "            \n",
    "            distanceValue = distanceValue + tempValue\n",
    "                        \n",
    "        distanceTemp.append(distanceValue)\n",
    "        \n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(numberOfDimensions):\n",
    "        centeredSampleValue = centeredSample[i]\n",
    "        \n",
    "        distanceValue = distanceTemp[i]\n",
    "        \n",
    "        tempValue = centeredSampleValue * distanceValue\n",
    "        \n",
    "        distance = distance + tempValue\n",
    "        \n",
    "    distance = - 0.5 * distance\n",
    "\n",
    "    # 5. obtain the pdf\n",
    "    pdf = scale * np.exp(distance)\n",
    "    \n",
    "    # 6. obtain the posterior pdf\n",
    "    posteriorPDF = mixtureWeight * pdf\n",
    "    \n",
    "    # 7. increment the pdf sum\n",
    "    gaussianPDFSum = gaussianPDFSum + posteriorPDF\n",
    "    \n",
    "    # 8. keep track of each pdf\n",
    "    gaussianPDF.append(posteriorPDF)\n",
    "\n",
    "print\n",
    "    \n",
    "# normalize each pdf by the sum for presentation to compare against scipy results\n",
    "print \"calculated Gaussian pdf\\n%s\" % (gaussianPDF / gaussianPDFSum)\n",
    "\n",
    "# don't normalize each pdf by the sum\n",
    "print \"calculated pr\\n%s\" % gaussianPDFSum\n",
    "\n",
    "print \"calculated log pr\\n%s\" % np.log(gaussianPDFSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mixture component index 0\n",
      "  mixture weight scalar 0.750000\n",
      "  mean vector\n",
      "[  9.95979962  10.04835949]\n",
      "  covariance matrix upper cholesky decomposition inverse matrix\n",
      "[[ 0.97654062  0.0954749 ]\n",
      " [ 0.          0.97863648]]\n",
      "  scale coefficient scalar 0.152101\n",
      "\n",
      "mixture component index 1\n",
      "  mixture weight scalar 0.250000\n",
      "  mean vector\n",
      "[ 0.22665544 -0.01327782]\n",
      "  covariance matrix upper cholesky decomposition inverse matrix\n",
      "[[ 1.16321213  0.16576253]\n",
      " [ 0.          1.07039451]]\n",
      "  scale coefficient scalar 0.198163\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "## calculate the constant values (these will all be hard-coded at compile-time) for method #2\n",
    "##############################################################################################\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy import constants\n",
    "\n",
    "numberOfMixtureComponents = g.n_components\n",
    "\n",
    "gmmParams = []\n",
    "\n",
    "for mixtureComponentIndex in range(numberOfMixtureComponents):\n",
    "    print \"\\nmixture component index %i\" % mixtureComponentIndex\n",
    "    \n",
    "    # 1. setup the parameters for the current mixture component\n",
    "    mixtureWeight = g.weights_[mixtureComponentIndex]\n",
    "\n",
    "    print \"  mixture weight scalar %f\" % mixtureWeight\n",
    "    \n",
    "    meanVector = g.means_[mixtureComponentIndex]\n",
    "    \n",
    "    print \"  mean vector\\n%s\" % meanVector\n",
    "    \n",
    "    covarianceMatrix = g.covars_[mixtureComponentIndex]\n",
    "    \n",
    "    numberOfDimensions = len(meanVector)\n",
    "    \n",
    "    covarianceUpperCholesky = linalg.cholesky(covarianceMatrix)\n",
    "    \n",
    "    inverseCovarianceUpperCholesky = linalg.inv(covarianceUpperCholesky)\n",
    "    \n",
    "    print \"  covariance matrix upper cholesky decomposition inverse matrix\\n%s\" % inverseCovarianceUpperCholesky\n",
    "    \n",
    "    diagProd = 1.\n",
    "    \n",
    "    for dimension in range(numberOfDimensions):\n",
    "        diag = covarianceUpperCholesky[dimension][dimension]\n",
    "        \n",
    "        diagProd = diagProd * diag\n",
    "    \n",
    "    scaleCoefficient = np.power((2 * constants.pi), numberOfDimensions)\n",
    "    \n",
    "    scaleCoefficient = 1.0 / np.sqrt(scaleCoefficient)\n",
    "    \n",
    "    scaleCoefficient = scaleCoefficient / diagProd\n",
    "    \n",
    "    print \"  scale coefficient scalar %f\" % scaleCoefficient\n",
    "        \n",
    "    # 2. store the parameters for the current mixture component\n",
    "    params = {\n",
    "        \"mixtureWeight\": mixtureWeight,\n",
    "        \"meanVector\": meanVector,\n",
    "        \"inverseCovarianceUpperCholesky\": inverseCovarianceUpperCholesky,\n",
    "        \"scaleCoefficient\": scaleCoefficient\n",
    "    }\n",
    "    \n",
    "    gmmParams.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n",
      "[ 4.62434536  2.38824359]\n",
      "\n",
      "scipy GMM pdf\n",
      "[[  3.94305515e-12   1.00000000e+00]]\n",
      "scipy GMM log pr\n",
      "[-21.53236115]\n",
      "scipy GMM pr\n",
      "[  4.45260707e-10]\n",
      "\n",
      "calculated Gaussian pdf\n",
      "[  3.94305515e-12   1.00000000e+00]\n",
      "calculated pr\n",
      "4.45260707191e-10\n",
      "calculated log pr\n",
      "-21.5323611465\n"
     ]
    }
   ],
   "source": [
    "##############################################################################################\n",
    "## method #2: use the stored inverse of the upper Cholesky decomposition of the covariance\n",
    "## matrix to compute the distance to each mixture component (linear algebra tricks)\n",
    "##############################################################################################\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "sample = (3 + np.random.randn(1, dimensions))[0]\n",
    "\n",
    "print \"sample\\n%s\" % sample\n",
    "\n",
    "print\n",
    "\n",
    "print \"scipy GMM pdf\\n%s\" % g.predict_proba([ sample ])\n",
    "\n",
    "print \"scipy GMM log pr\\n%s\" % g.score([ sample ])\n",
    "\n",
    "print \"scipy GMM pr\\n%s\" % np.exp(g.score([ sample ]))\n",
    "\n",
    "# store the pdf of each mixture component\n",
    "gaussianPDF = []\n",
    "\n",
    "# store the sum of the pdfs\n",
    "gaussianPDFSum = 0\n",
    "\n",
    "for mixtureComponentIndex in range(numberOfMixtureComponents):\n",
    "    # 1. get the given parameters for this mixture component:\n",
    "    params = gmmParams[mixtureComponentIndex]\n",
    "    \n",
    "    mixtureWeight = params[\"mixtureWeight\"]\n",
    "\n",
    "    meanVector = params[\"meanVector\"]\n",
    "        \n",
    "    numberOfDimensions = len(meanVector)\n",
    "    \n",
    "    inverseCovarianceUpperCholesky = params[\"inverseCovarianceUpperCholesky\"]\n",
    "    \n",
    "    scaleCoefficient = params[\"scaleCoefficient\"]\n",
    "    \n",
    "    # 2. center the data sample:\n",
    "    centeredSample = []\n",
    "    \n",
    "    for i in range(numberOfDimensions):\n",
    "        sampleValue = sample[i]\n",
    "        \n",
    "        meanValue = meanVector[i]\n",
    "        \n",
    "        centeredSampleValue = sampleValue - meanValue\n",
    "        \n",
    "        centeredSample.append(centeredSampleValue)\n",
    "    \n",
    "    # 3. perform the Mahalanobis distance calculation using the \n",
    "    # inverse of the Cholesky decomposition of the covariance matrix\n",
    "    # see mvnpdf.m for method\n",
    "    distance = 0\n",
    "    \n",
    "    for i in range(numberOfDimensions):\n",
    "        distanceValue = 0\n",
    "        \n",
    "        for j in range(numberOfDimensions):\n",
    "            centeredSampleValue = centeredSample[j]\n",
    "            \n",
    "            inverseCovarianceUpperCholeskyValue = inverseCovarianceUpperCholesky[j][i]\n",
    "            \n",
    "            tempValue = centeredSampleValue * inverseCovarianceUpperCholeskyValue\n",
    "            \n",
    "            distanceValue = distanceValue + tempValue\n",
    "            \n",
    "        distanceValue = distanceValue * distanceValue\n",
    "                        \n",
    "        distance = distance + distanceValue\n",
    "                \n",
    "    distance = - 0.5 * distance\n",
    "\n",
    "    # 4. obtain the pdf\n",
    "    pdf = scaleCoefficient * np.exp(distance)\n",
    "    \n",
    "    # 5. obtain the posterior pdf\n",
    "    posteriorPDF = mixtureWeight * pdf\n",
    "    \n",
    "    # 6. increment the pdf sum\n",
    "    gaussianPDFSum = gaussianPDFSum + posteriorPDF\n",
    "    \n",
    "    # 7. keep track of each pdf\n",
    "    gaussianPDF.append(posteriorPDF)\n",
    "\n",
    "print\n",
    "    \n",
    "# normalize each pdf by the sum for presentation to compare against scipy results\n",
    "print \"calculated Gaussian pdf\\n%s\" % (gaussianPDF / gaussianPDFSum)\n",
    "\n",
    "# don't normalize each pdf by the sum\n",
    "print \"calculated pr\\n%s\" % gaussianPDFSum\n",
    "\n",
    "print \"calculated log pr\\n%s\" % np.log(gaussianPDFSum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
